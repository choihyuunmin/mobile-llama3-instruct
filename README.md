forked from https://github.com/DNLab2024/Mobile-LLaMA


Evaluation Table (Averages by Model):
+---------------+--------+-------------------+------------------+  
|     Model     | pass@1 | execution_time(s) | memory_usage(MB) |  
+---------------+--------+-------------------+------------------+  
|    GPT-3.5    |  0.93  |       4.60        |       2.54       |  
|     Llama3    |  0.93  |       4.25        |       4.17       |  
| Mobile-Llama3 |  1.00  |       1.70        |       1.67       |  
+---------------+--------+-------------------+------------------+  


![Figure_1](https://github.com/user-attachments/assets/cef49a8d-e9f5-4c36-80ea-cd047d8899c3)
![Figure_2](https://github.com/user-attachments/assets/537e9ec2-2baa-48cc-8392-63b5c074cd8b)
![Figure_3](https://github.com/user-attachments/assets/1159f89d-ee31-48b3-acc6-534eee3f6978)
